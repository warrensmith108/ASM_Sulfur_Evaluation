{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64a0fa45-f9ae-4338-bb1d-16776ba12cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import glob\n",
    "import os\n",
    "import netCDF4 as nc4\n",
    "from scipy.interpolate import interp1d\n",
    "import math\n",
    "import matplotlib.tri as tri\n",
    "#from plot_season import make_hist\n",
    "import pickle as pkl\n",
    "import sim_name_remap as map\n",
    "import var_config as vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07a83fc3-11ce-4865-8bc6-b4164faa98be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_names = ['MAM4_CESM3_test']   #'MAM4_MEIC_SO2','MAM4_CAMS6.2_SO2','MAM4_MEIC_110L']#,'CARMA_MEIC_SO2_bins','CARMA_CAMS_SO2_bins']  #,    #  'MAM4_MEIC_SO2_ZMKE']  #,,]  ,\n",
    "var_names = ['so4_a1','so4_a2','so4_a3','SO2']#'SO4']#,'SO2']#,'CO','O3']#,OA','BC','N2O','NOX','C2H6','C3H8','CFC11','CFC113','CH3CCL3','CCL4','CFC115','CFC12','CH2BR2','CH3BR','CH3CL',\\\n",
    "            #'CF2CLBR','HCFC141B','HCFC142B','HCFC22','CFC114','CF3BR','CH2CL2']\n",
    "            #[,'soa1_a1','soa1_a2','soa2_a1','soa2_a2','soa3_a1','soa3_a2',\\\n",
    "            #'soa4_a1','soa4_a2','soa5_a1','soa5_a2','pom_a1','num_a1','num_a2','num_a3','dst_a1',\\\n",
    "            # 'dst_a2','dst_a3','bc_a1','ncl_a1','ncl_a2','ncl_a3']\n",
    "\n",
    "lon_bndss = [[125,140]]    # [95,135],[125,140],[90,110]]#,[65,95],]]  ]#,    \n",
    "lat_bndss = [[25,38]]    # [30,50],[25,38],[25,40]]#]#,,[30,40]]   \n",
    "#lon_bndss = [[75,120]]\n",
    "#lat_bndss = [[25,40]]\n",
    "\n",
    "do_prof = 1  # Determines if the code will calculate mean profiles of model data to compare against aircraft\n",
    "SAVEDIR = '/glade/derecho/scratch/wsmith/carma_vars/'\n",
    "prs_lvls = [100.]   # This is used as a filter for screening in vs out of anticyclone\n",
    "gph_asmas = [[16730,16810]]\n",
    "z_prof = np.arange(0,25,0.5)  # Altitude profile (km)\n",
    "th_prof = np.arange(300,600,5)  # Theta profile (K)\n",
    "#delta_th_prof = np.arange(-100,101,5)\n",
    "delta_z_prof = np.arange(-20,10.1,0.5) # Tropopause-relative altitude profile (km)\n",
    "Rdcp = 287.06/1004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87062a2e-fcf4-4a28-86df-1ea288adf4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True sim name:  /glade/derecho/scratch/tilmes/archive/f.e30.alpha07e.ctsm5.3.075.sp.nudged.2016_2018_MTt4s.ne30.002/atm/hist/f.e30*.h0a.2022-08*\n",
      "/glade/derecho/scratch/tilmes/archive/f.e30.alpha07e.ctsm5.3.075.sp.nudged.2016_2018_MTt4s.ne30.002/atm/hist/f.e30*.h0a.2022-08*\n",
      "so4_a1  files already exist, skipping them...\n",
      "so4_a2  files already exist, skipping them...\n",
      "so4_a3  files already exist, skipping them...\n",
      "MAM4_CESM3_test ***** ['SO2'] ***** [125, 140] ***** [25, 38]\n"
     ]
    }
   ],
   "source": [
    "for sim_name in sim_names:\n",
    "\n",
    "    true_sim_path = map.remap[sim_name]\n",
    "    print('True sim name: ', true_sim_path)\n",
    "\n",
    "    print(true_sim_path)\n",
    "\n",
    "    FILES = sorted(glob.glob(true_sim_path))\n",
    "    #print(FILES)\n",
    "\n",
    "    for ltln in range(len(lon_bndss)):\n",
    "\n",
    "        lon_bnds = lon_bndss[ltln]\n",
    "        lat_bnds = lat_bndss[ltln]\n",
    "\n",
    "        # if true_sim_name[0:5] == 'CARMA': \n",
    "        #    DATAROOT = '/data/wsmith/forecasts/2022_ACCLIP_' + sim_name\n",
    "        #    var_strs = [['MXSO4MR','SO4PRMR'],['MXOCMR','MXSOAMR'],['MXBCMR'],['CO'],['SO2'],['BIGALK'],['C2H6'],['C3H8'],['CH4'],['CH2O'],['H2O2'],['CH3OOH'],['NH3'],['OH']]                  \n",
    "            \n",
    "        for v in range(len(var_names)):\n",
    "                            \n",
    "            var_name = var_names[v]\n",
    "\n",
    "            zSAVEFILE = SAVEDIR + var_name + 'zprofiles_' + sim_name + '_' + str(lon_bnds) + '_' + str(lat_bnds) + '.pkl'\n",
    "\n",
    "            if os.path.isfile(zSAVEFILE):\n",
    "                print(var_name, ' files already exist, skipping them...')\n",
    "            \n",
    "            else: \n",
    "\n",
    "                if sim_name[0:4] == 'MAM4': \n",
    "                    if var_name in vc.var_info: var_str = vc.var_info[var_name]['MAM4_vars']\n",
    "                    else: var_str = var_name\n",
    "                if sim_name[0:5] == 'CARMA': var_str = vc.var_info[var_name]['CARMA_vars']\n",
    "                \n",
    "                #var_str = var_strs[v]\n",
    "                #var_mod = var_mods[v]\n",
    "                #rng = rngs[v]\n",
    "    \n",
    "                print(sim_name, '*****', var_str, '*****', lon_bnds, '*****', lat_bnds)\n",
    "    \n",
    "                file0 = nc4.Dataset(FILES[0])\n",
    "    \n",
    "                # Account for the fact that we might have two model variables that we need to combine\n",
    "                if isinstance(var_str, str): var = file0.variables[var_str][:]\n",
    "                if isinstance(var_str, list):\n",
    "                    var = file0.variables[var_str[0]][:]\n",
    "                    for sub_v in range(len(var_str)-1):\n",
    "                        sub_var = file0.variables[var_str[sub_v+1]][:]\n",
    "                        var = var + sub_var\n",
    "                    \n",
    "                temp   = file0.variables['T'][:]\n",
    "                PS     = file0.variables['PS'][:]\n",
    "                TROP_P = file0.variables['TROP_P'][:]   # This is not included in the output, but can be uncommented later for other simulations\n",
    "                gph    = file0.variables['Z3'][:]\n",
    "                #U      = file0.variables['U'][:]\n",
    "                #V      = file0.variables['V'][:]\n",
    "    \n",
    "                for f in range(len(FILES)-1):\n",
    "                    \n",
    "                    file = nc4.Dataset(FILES[f+1])\n",
    "                    \n",
    "                    if isinstance(var_str, str): curr_var = file.variables[var_str][:]\n",
    "                    if isinstance(var_str, list):\n",
    "                        curr_var = file.variables[var_str[0]][:]\n",
    "                        for sub_v in range(len(var_str)-1):\n",
    "                            curr_sub_var = file.variables[var_str[sub_v+1]][:]\n",
    "                            curr_var = curr_var + curr_sub_var\n",
    "                    \n",
    "                    var = np.append(var, curr_var, axis=0)\n",
    "                    \n",
    "                    temp   = np.append(temp, file.variables['T'][:], axis=0)\n",
    "                    PS     = np.append(PS, file.variables['PS'][:], axis=0)\n",
    "                    #U      = np.append(U, file.variables['U'][:], axis=0)   # We don't need U and V for this, they can be read in as their own variable\n",
    "                    #V      = np.append(V, file.variables['V'][:], axis=0)\n",
    "                    TROP_P = np.append(TROP_P, file.variables['TROP_P'][:], axis=0)\n",
    "                    gph    = np.append(gph, file.variables['Z3'][:], axis=0)\n",
    "                    \n",
    "                #var = var*var_mod    # Moving this to the plotting script\n",
    "                NT = np.shape(var)[0]\n",
    "                \n",
    "                PS_mean = np.mean(PS, axis=0)\n",
    "    \n",
    "                for p in range(len(prs_lvls)):\n",
    "                \n",
    "                    # Set up arrays so we can save the non-interpolated values\n",
    "                    var_1d = []\n",
    "                    troprelz_1d = []\n",
    "                    z_1d = []\n",
    "                    theta_1d = []\n",
    "                    tropreltheta_1d = []\n",
    "                \n",
    "                    prs_lvl = prs_lvls[p]\n",
    "                    gph_asma = gph_asmas[p]\n",
    "                    TROP_gph_array = []\n",
    "                    TROP_theta_array = []\n",
    "    \n",
    "                    lon  = file0.variables['lon'][:]\n",
    "                    lat  = file0.variables['lat'][:]\n",
    "                    lev  = file0.variables['lev'][:]\n",
    "                    hyam = file0.variables['hyam'][:]\n",
    "                    hybm = file0.variables['hybm'][:]\n",
    "                    NZ   = len(lev)\n",
    "    \n",
    "                    var_lvls_f = interp1d(lev, np.arange(len(lev)), bounds_error=None, fill_value=-999)\n",
    "                    var_lev_index_frac = var_lvls_f(prs_lvl)\n",
    "                    var_lev_index_dec  = var_lev_index_frac - math.floor(var_lev_index_frac)\n",
    "                    var_lev_index_flr  = math.floor(var_lev_index_frac)\n",
    "    \n",
    "                    var_zprofs_in  = np.zeros((1,len(z_prof)))-999\n",
    "                    var_zprofs_out = np.zeros((1,len(z_prof)))-999\n",
    "    \n",
    "                    var_thprofs_in  = np.zeros((1,len(th_prof)))-999\n",
    "                    var_thprofs_out = np.zeros((1,len(th_prof)))-999\n",
    "                    \n",
    "                    var_troprelzprofs_in  = np.zeros((1,len(delta_z_prof)))-999\n",
    "                    var_troprelzprofs_out = np.zeros((1,len(delta_z_prof)))-999\n",
    "                    \n",
    "                    #var_troprelthprofs_in  = np.zeros((1,len(delta_th_prof)))-999\n",
    "                    #var_troprelthprofs_out = np.zeros((1,len(delta_th_prof)))-999\n",
    "                    \n",
    "                    if len(lon) < 5000.:  # Structured grid\n",
    "    \n",
    "                        # Trim the plot to just the lon/lat boundaries\n",
    "                        lon_ind0 = np.min(np.where(lon >= lon_bnds[0])[0])\n",
    "                        lon_ind1 = np.max(np.where(lon <= lon_bnds[1])[0])+1\n",
    "                        lat_ind0 = np.min(np.where(lat >= lat_bnds[0])[0])\n",
    "                        lat_ind1 = np.max(np.where(lat <= lat_bnds[1])[0])+1\n",
    "                        \n",
    "                        var_sub = var[:,:,lat_ind0:lat_ind1,lon_ind0:lon_ind1]\n",
    "                        TROP_P_sub = TROP_P[:,lat_ind0:lat_ind1,lon_ind0:lon_ind1]\n",
    "                        PS_sub = PS[:,lat_ind0:lat_ind1,lon_ind0:lon_ind1]\n",
    "                        temp_sub = temp[:,:,lat_ind0:lat_ind1,lon_ind0:lon_ind1]\n",
    "                        gph_sub = gph[:,:,lat_ind0:lat_ind1,lon_ind0:lon_ind1]\n",
    "                        var_lev = (1-var_lev_index_dec)*var_sub[:,var_lev_index_flr,:,:] + var_lev_index_dec*var_sub[:,var_lev_index_flr+1,:,:]   \n",
    "                        gph_lev = (1-var_lev_index_dec)*gph_sub[:,var_lev_index_flr,:,:] + var_lev_index_dec*gph_sub[:,var_lev_index_flr+1,:,:] \n",
    "                        #U_lev = (1-var_lev_index_dec)*U[:,var_lev_index_flr,lat_ind0:lat_ind1,lon_ind0:lon_ind1] + var_lev_index_dec*U[:,var_lev_index_flr+1,lat_ind0:lat_ind1,lon_ind0:lon_ind1] \n",
    "                        #V_lev = (1-var_lev_index_dec)*V[:,var_lev_index_flr,lat_ind0:lat_ind1,lon_ind0:lon_ind1] + var_lev_index_dec*V[:,var_lev_index_flr+1,lat_ind0:lat_ind1,lon_ind0:lon_ind1] \n",
    "                        \n",
    "                        lon_sub = lon[lon_ind0:lon_ind1]\n",
    "                        lat_sub = lat[lat_ind0:lat_ind1]\n",
    "                        \n",
    "                        if do_prof:\n",
    "                        \n",
    "                            ################ Compute average profiles within and outside the anticyclone\n",
    "                            for t in range(NT):\n",
    "                                #print('****************  t = ', t)\n",
    "    \n",
    "                                # At each time step, we will generate a new array of profiles so we can add that to the master array all at one time\n",
    "                                curr_var_zprofs_in  = np.zeros((1,len(z_prof)))-999\n",
    "                                curr_var_zprofs_out = np.zeros((1,len(z_prof)))-999\n",
    "    \n",
    "                                curr_var_thprofs_in  = np.zeros((1,len(th_prof)))-999\n",
    "                                curr_var_thprofs_out = np.zeros((1,len(th_prof)))-999\n",
    "                                \n",
    "                                curr_var_troprelzprofs_in  = np.zeros((1,len(delta_z_prof)))-999\n",
    "                                curr_var_troprelzprofs_out = np.zeros((1,len(delta_z_prof)))-999\n",
    "    \n",
    "                                #curr_var_troprelthprofs_in  = np.zeros((1,len(delta_th_prof)))-999\n",
    "                                #curr_var_troprelthprofs_out = np.zeros((1,len(delta_th_prof)))-999\n",
    "                            \n",
    "                                lt_in = []\n",
    "                                ln_in = []\n",
    "                                lt_out = []\n",
    "                                ln_out = []\n",
    "                                \n",
    "                                for lt in range(len(lat_sub)):\n",
    "                                    for ln in range(len(lon_sub)):\n",
    "                                \n",
    "                                        # Unfortunately these simulations are on \"raw\" model levels which means we need to account for topography.  \n",
    "                                        curr_TROP_P = TROP_P_sub[t,lt,ln]/100.\n",
    "                                        curr_PS = PS_sub[t,lt,ln] \n",
    "                                        curr_plev = (hyam*1.0e5 + hybm*curr_PS)/100.\n",
    "                                        curr_gph_lev = gph_lev[t,lt,ln]                            \n",
    "                                        curr_gphprof = np.squeeze(gph_sub[t,:,lt,ln])                            \n",
    "                                        curr_varprof = np.squeeze(var_sub[t,:,lt,ln])\n",
    "                                        \n",
    "                                        plev_f = interp1d(curr_plev, np.arange(len(curr_plev)), bounds_error=False, fill_value=-999)\n",
    "                                        trop_index_frac = plev_f(curr_TROP_P)\n",
    "                                        gph_f = interp1d(np.arange(len(curr_gphprof)), curr_gphprof, bounds_error=False, fill_value=-999)\n",
    "                                        curr_TROP_gph = gph_f(trop_index_frac)\n",
    "                                        TROP_gph_array.append(curr_TROP_gph)\n",
    "    \n",
    "                                        curr_deltazlev = (curr_gphprof - curr_TROP_gph)/1.0e3\n",
    "                                        f_z = interp1d(curr_gphprof*1.e-3, curr_varprof, bounds_error=False, fill_value=-999)\n",
    "                                        f_deltaz = interp1d(curr_deltazlev, curr_varprof, bounds_error=False, fill_value=-999)                                                                                                                                  \n",
    "                                        \n",
    "                                        curr_tempprof = np.squeeze(temp_sub[t,:,lt,ln])\n",
    "                                        curr_thetaprof = curr_tempprof*((1000./curr_plev)**Rdcp)\n",
    "                                        f_th = interp1d(curr_thetaprof, curr_varprof, bounds_error=False, fill_value=-999)\n",
    "    \n",
    "                                        #th_f = interp1d(np.arange(len(curr_thetaprof)), curr_thetaprof, bounds_error=False, fill_value=-999)\n",
    "                                        #curr_TROP_theta = th_f(trop_index_frac)  \n",
    "                                        #TROP_theta_array.append(curr_TROP_theta)\n",
    "                                        #curr_TROP_theta = curr_thetaprof[TROP_nrst_index]  # Current tropopause in theta coordinates\n",
    "                                        #curr_deltathetaprof = curr_thetaprof - curr_TROP_theta\n",
    "                                        #f_deltatheta = interp1d(curr_deltathetaprof, curr_varprof, bounds_error=False, fill_value=-999)  # The 9s are intentional to flag missing data as negative (missing)                                          \n",
    "    \n",
    "                                        var_1d.extend(curr_varprof)\n",
    "                                        z_1d.extend(curr_gphprof*1.e-3)\n",
    "                                        #troprelz_1d.extend(curr_deltazlev)\n",
    "                                        theta_1d.extend(curr_thetaprof)\n",
    "                                        #tropreltheta_1d.extend(curr_deltathetaprof)\n",
    "    \n",
    "                                        if curr_gph_lev >= np.mean(gph_asma): \n",
    "                                            #ln_in.append(ln)\n",
    "                                            #lt_in.append(lt)\n",
    "                                            #var_profs_in_theta  = np.append(var_profs_in_theta, f_deltatheta(delta_th_prof)[None,:], axis=0)\n",
    "                                            curr_var_zprofs_in = np.append(curr_var_zprofs_in, f_z(z_prof)[None,:], axis=0)\n",
    "                                            curr_var_thprofs_in = np.append(curr_var_thprofs_in, f_th(th_prof)[None,:], axis=0)\n",
    "                                            #curr_var_troprelthprofs_in = np.append(curr_var_troprelthprofs_in, f_deltatheta(delta_th_prof)[None,:], axis=0)\n",
    "                                            curr_var_troprelzprofs_in  = np.append(curr_var_troprelzprofs_in, f_deltaz(delta_z_prof)[None,:], axis=0)\n",
    "                                        else:\n",
    "                                            #ln_out.append(ln)\n",
    "                                            #lt_out.append(lt)\n",
    "                                            #var_profs_out_theta = np.append(var_profs_out_theta, f_deltatheta(delta_th_prof)[None,:], axis=0)\n",
    "                                            curr_var_zprofs_out  = np.append(curr_var_zprofs_out, f_z(z_prof)[None,:], axis=0)    \n",
    "                                            curr_var_thprofs_out = np.append(curr_var_thprofs_out, f_th(th_prof)[None,:], axis=0)                                    \n",
    "                                            #curr_var_troprelthprofs_out = np.append(curr_var_troprelthprofs_out, f_deltatheta(delta_th_prof)[None,:], axis=0)\n",
    "                                            curr_var_troprelzprofs_out  = np.append(curr_var_troprelzprofs_out, f_deltaz(delta_z_prof)[None,:], axis=0)                                                                \n",
    "                                \n",
    "                                var_zprofs_in = np.append(var_zprofs_in, curr_var_zprofs_in[1:,:], axis=0)\n",
    "                                var_zprofs_out = np.append(var_zprofs_out, curr_var_zprofs_out[1:,:], axis=0)                        \n",
    "    \n",
    "                                var_thprofs_in = np.append(var_thprofs_in, curr_var_thprofs_in[1:,:], axis=0)\n",
    "                                var_thprofs_out = np.append(var_thprofs_out, curr_var_thprofs_out[1:,:], axis=0) \n",
    "                                \n",
    "                                var_troprelzprofs_in = np.append(var_troprelzprofs_in, curr_var_troprelzprofs_in[1:,:], axis=0)\n",
    "                                var_troprelzprofs_out = np.append(var_troprelzprofs_out, curr_var_troprelzprofs_out[1:,:], axis=0)\n",
    "    \n",
    "                                #var_troprelthprofs_in  = np.append(var_troprelthprofs_in, curr_var_troprelthprofs_in[1:,:], axis=0)\n",
    "                                #var_troprelthprofs_out = np.append(var_troprelthprofs_out, curr_var_troprelthprofs_out[1:,:], axis=0)\n",
    "                                \n",
    "                                #var_profs_in  = np.append(var_profs_in, var_sub[t,:,lt_in,ln_in], axis=0)\n",
    "                                #var_profs_out = np.append(var_profs_out, var_sub[t,:,lt_out,ln_out], axis=0)\n",
    "                        \n",
    "                            #print(np.shape(var_zprofs_in))\n",
    "                            #print(np.shape(var_zprofs_out))\n",
    "                            \n",
    "                        PS_plot = np.mean(PS_sub, axis=0)\n",
    "                    \n",
    "                    else:  # Regional refinement\n",
    "    \n",
    "                        print('This is a regionally refined grid - converting to rectangular grid...')\n",
    "                        xi = np.linspace(0.0, 359.75, 1440)  # For now, we define a quarter degree rectangular grid to interpolate to\n",
    "                        yi = np.linspace(-90, 90, 721)\n",
    "                        triang = tri.Triangulation(lon, lat)\n",
    "                        Xi, Yi = np.meshgrid(xi, yi)    \n",
    "                        \n",
    "                        #var_lev = np.zeros((1, len(yi), len(xi)))\n",
    "                        #gph_lev = np.zeros((1, len(yi), len(xi)))\n",
    "                        #U_lev = np.zeros((1, len(yi), len(xi)))\n",
    "                        #V_lev = np.zeros((1, len(yi), len(xi)))\n",
    "                        \n",
    "                        PS_interpolator = tri.LinearTriInterpolator(triang, PS_mean)   \n",
    "                        PS_plot = PS_interpolator(Xi, Yi)\n",
    "                            \n",
    "                        for t in range(NT):\n",
    "                            #print('t = ', t)\n",
    "                            \n",
    "                            #var_arr = np.squeeze((1-var_lev_index_dec)*var[t,var_lev_index_flr,:] + var_lev_index_dec*var[t,var_lev_index_flr+1,:])\n",
    "                            #var_interpolator = tri.LinearTriInterpolator(triang, var_arr)   \n",
    "                            #var_lev = np.append(var_lev, var_interpolator(Xi, Yi)[None,:], axis=0)\n",
    "                            \n",
    "                            gph_arr = np.squeeze((1-var_lev_index_dec)*gph[t,var_lev_index_flr,:] + var_lev_index_dec*gph[t,var_lev_index_flr+1,:])\n",
    "                            #gph_interpolator = tri.LinearTriInterpolator(triang, gph_arr)\n",
    "                            #gph_lev = np.append(gph_lev, gph_interpolator(Xi, Yi)[None,:], axis=0)\n",
    "    \n",
    "                            #U_arr = np.squeeze((1-var_lev_index_dec)*U[t,var_lev_index_flr,:] + var_lev_index_dec*U[t,var_lev_index_flr+1,:])\n",
    "                            #U_interpolator = tri.LinearTriInterpolator(triang, U_arr)\n",
    "                            #U_lev = np.append(U_lev, U_interpolator(Xi, Yi)[None,:], axis=0)\n",
    "    \n",
    "                            #V_arr = np.squeeze((1-var_lev_index_dec)*V[t,var_lev_index_flr,:] + var_lev_index_dec*V[t,var_lev_index_flr+1,:])\n",
    "                            #V_interpolator = tri.LinearTriInterpolator(triang, V_arr)   \n",
    "                            #V_lev = np.append(V_lev, V_interpolator(Xi, Yi)[None,:], axis=0)\n",
    "                            \n",
    "                            pts_in = []  # For each time step, we will save the points inside and outside the monsoon\n",
    "                            pts_out = []\n",
    "    \n",
    "                            # At each time step, we will generate a new array of profiles so we can add that to the master array all at one time\n",
    "                            curr_var_zprofs_in  = np.zeros((1,len(z_prof)))-999\n",
    "                            curr_var_zprofs_out = np.zeros((1,len(z_prof)))-999\n",
    "    \n",
    "                            curr_var_thprofs_in  = np.zeros((1,len(th_prof)))-999\n",
    "                            curr_var_thprofs_out = np.zeros((1,len(th_prof)))-999\n",
    "                            \n",
    "                            #curr_var_troprelzprofs_in  = np.zeros((1,len(delta_z_prof)))-999\n",
    "                            #curr_var_troprelzprofs_out = np.zeros((1,len(delta_z_prof)))-999\n",
    "    \n",
    "                            #curr_var_troprelthprofs_in  = np.zeros((1,len(delta_th_prof)))-999\n",
    "                            #curr_var_troprelthprofs_out = np.zeros((1,len(delta_th_prof)))-999\n",
    "                            \n",
    "                            if do_prof:\n",
    "                            \n",
    "                                for pt in range(len(lon)):\n",
    "                                \n",
    "                                    if pt % 10000 == 0: print(pt, ' of ', len(lon))\n",
    "                                   \n",
    "                                    curr_lon = lon[pt]\n",
    "                                    curr_lat = lat[pt]\n",
    "                                    \n",
    "                                    if curr_lon >= lon_bnds[0] and curr_lon <= lon_bnds[1] and curr_lat >= lat_bnds[0] and curr_lat <= lat_bnds[1]:\n",
    "    \n",
    "                                        # Unfortunately these simulations are on \"raw\" model levels which means we need to account for topography.  \n",
    "                                        curr_TROP_P = TROP_P[t,pt]/100.\n",
    "                                        curr_PS = PS[t,pt] \n",
    "                                        curr_plev = (hyam*1.0e5 + hybm*curr_PS)/100.\n",
    "                                        curr_gph_lev = gph_arr[pt]       \n",
    "                                        curr_gphprof = np.squeeze(gph[t,:,pt])                            \n",
    "                                        curr_varprof = np.squeeze(var[t,:,pt])\n",
    "                                        \n",
    "                                        plev_f = interp1d(curr_plev, np.arange(len(curr_plev)), bounds_error=False, fill_value=-999)\n",
    "                                        trop_index_frac = plev_f(curr_TROP_P)\n",
    "                                        gph_f = interp1d(np.arange(len(curr_gphprof)), curr_gphprof, bounds_error=False, fill_value=-999)\n",
    "                                        curr_TROP_gph = gph_f(trop_index_frac)\n",
    "                                        TROP_gph_array.append(curr_TROP_gph)\n",
    "                                        \n",
    "                                        #curr_deltazlev = (curr_gphprof - curr_TROP_gph)/1.0e3\n",
    "                                        f_z = interp1d(curr_gphprof*1.e-3, curr_varprof, bounds_error=False, fill_value=-999)\n",
    "                                        f_deltaz = interp1d(curr_deltazlev, curr_varprof, bounds_error=False, fill_value=-999)  \n",
    "                                     \n",
    "                                        curr_tempprof = np.squeeze(temp[t,:,pt])                        \n",
    "                                        curr_thetaprof = curr_tempprof*((1000./curr_plev)**Rdcp) \n",
    "                                        f_th = interp1d(curr_thetaprof, curr_varprof, bounds_error=False, fill_value=-999)\n",
    "                                        \n",
    "                                        th_f = interp1d(np.arange(len(curr_thetaprof)), curr_thetaprof, bounds_error=False, fill_value=-999)\n",
    "                                        ##curr_TROP_theta = th_f(trop_index_frac)\n",
    "                                        #TROP_theta_array.append(curr_TROP_theta)                            \n",
    "                                        #curr_TROP_theta = curr_thetaprof[TROP_nrst_index]  # Current tropopause in theta coordinates\n",
    "                                        #curr_deltathetaprof = curr_thetaprof - curr_TROP_theta\n",
    "                                        #f_deltatheta = interp1d(curr_deltathetaprof, curr_varprof, bounds_error=False, fill_value=-999)  # The 9s are intentional to flag data below the surface as negative\n",
    "    \n",
    "                                        curr_gph = gph_arr[pt]\n",
    "                                        \n",
    "                                        var_1d.extend(curr_varprof)\n",
    "                                        z_1d.extend(curr_gphprof*1.e-3)\n",
    "                                        #troprelz_1d.extend(curr_deltazlev)\n",
    "                                        theta_1d.extend(curr_thetaprof)\n",
    "                                        #tropreltheta_1d.extend(curr_deltathetaprof)\n",
    "                                        \n",
    "                                        if curr_gph >= np.mean(gph_asma): \n",
    "                                            #pts_in.append(pt)\n",
    "                                            #var_profs_in_theta  = np.append(var_profs_in_theta, f_deltatheta(delta_theta_prof)[None,:], axis=0) \n",
    "                                            curr_var_zprofs_in = np.append(curr_var_zprofs_in, f_z(z_prof)[None,:], axis=0)\n",
    "                                            curr_var_thprofs_in = np.append(curr_var_thprofs_in, f_th(th_prof)[None,:], axis=0)\n",
    "                                            #curr_var_troprelthprofs_in = np.append(curr_var_troprelthprofs_in, f_deltatheta(delta_th_prof)[None,:], axis=0)\n",
    "                                            #curr_var_troprelzprofs_in  = np.append(curr_var_troprelzprofs_in, f_deltaz(delta_z_prof)[None,:], axis=0)                                \n",
    "                                        else: \n",
    "                                            #pts_out.append(pt)\n",
    "                                            #var_profs_out_theta = np.append(var_profs_out_theta, f_deltatheta(delta_theta_prof)[None,:], axis=0)\n",
    "                                            curr_var_zprofs_out = np.append(curr_var_zprofs_out, f_z(z_prof)[None,:], axis=0)\n",
    "                                            curr_var_thprofs_out = np.append(curr_var_thprofs_out, f_th(th_prof)[None,:], axis=0)\n",
    "                                            #curr_var_troprelthprofs_out = np.append(curr_var_troprelthprofs_out, f_deltatheta(delta_th_prof)[None,:], axis=0)\n",
    "                                            #curr_var_troprelzprofs_out  = np.append(curr_var_troprelzprofs_out, f_deltaz(delta_z_prof)[None,:], axis=0)                    \n",
    "    \n",
    "                                var_zprofs_in = np.append(var_zprofs_in, curr_var_zprofs_in[1:,:], axis=0)\n",
    "                                var_zprofs_out = np.append(var_zprofs_out, curr_var_zprofs_out[1:,:], axis=0)  \n",
    "    \n",
    "                                var_thprofs_in = np.append(var_thprofs_in, curr_var_thprofs_in[1:,:], axis=0)\n",
    "                                var_thprofs_out = np.append(var_thprofs_out, curr_var_thprofs_out[1:,:], axis=0)\n",
    "                                \n",
    "                                #var_troprelzprofs_in = np.append(var_troprelzprofs_in, curr_var_troprelzprofs_in[1:,:], axis=0)\n",
    "                                #var_troprelzprofs_out = np.append(var_troprelzprofs_out, curr_var_troprelzprofs_out[1:,:], axis=0)\n",
    "    \n",
    "                                #var_troprelthprofs_in  = np.append(var_troprelthprofs_in, curr_var_troprelthprofs_in[1:,:], axis=0)\n",
    "                                #var_troprelthprofs_out = np.append(var_troprelthprofs_out, curr_var_troprelthprofs_out[1:,:], axis=0)\n",
    "                                                                                                                                  \n",
    "                        #var_lev = var_lev[1:,:,:]\n",
    "                        #gph_lev = gph_lev[1:,:,:]\n",
    "                        #U_lev = U_lev[1:,:,:]\n",
    "                        #V_lev = V_lev[1:,:,:]\n",
    "                        \n",
    "                        lon = xi\n",
    "                        lat = yi\n",
    "                        \n",
    "                        lon_sub = lon\n",
    "                        lat_sub = lat\n",
    "                        #lon_ind0 = np.min(np.where(lon >= lon_bnds[0])[0])\n",
    "                        #lon_ind1 = np.max(np.where(lon <= lon_bnds[1])[0])+1\n",
    "                        #lat_ind0 = np.min(np.where(lat >= lat_bnds[0])[0])\n",
    "                        #lat_ind1 = np.max(np.where(lat <= lat_bnds[1])[0])+1\n",
    "    \n",
    "                    #var_lev_mean = np.mean(var_lev, axis=0)\n",
    "                    #gph_lev_mean = np.mean(gph_lev, axis=0)\n",
    "                    #U_lev_mean = np.mean(U_lev, axis=0)\n",
    "                    #V_lev_mean = np.mean(V_lev, axis=0)       \n",
    "                    \n",
    "                    \n",
    "                    ################# Save the profile information\n",
    "                    \n",
    "                    #with open(SAVEDIR + var_name + 'profiles_' + sim + '_' + str(lon_bnds) + '_' + str(lat_bnds) + '_' + str(int(prs_lvl)) + 'GPHfilter.pkl', 'wb') as f:\n",
    "                    #    pkl.dump((var_profs_in[1:,:], var_profs_out[1:,:], lev, gph_asma), f)\n",
    "    \n",
    "                    if do_prof:\n",
    "    \n",
    "                        with open(zSAVEFILE, 'wb') as f:\n",
    "                            pkl.dump((np.append(var_zprofs_in[1:,:], var_zprofs_out[1:,:], axis=0), TROP_gph_array, z_prof), f)\n",
    "    \n",
    "                        with open(SAVEDIR + var_name + 'thetaprofiles_' + sim_name + '_' + str(lon_bnds) + '_' + str(lat_bnds) + '.pkl', 'wb') as f:\n",
    "                            pkl.dump((np.append(var_thprofs_in[1:,:], var_thprofs_out[1:,:], axis=0), TROP_theta_array, th_prof), f)\n",
    "                            \n",
    "                        #with open(SAVEDIR + var_name + 'troprelthetaprofiles_' + sim + '_' + str(lon_bnds) + '_' + str(lat_bnds) + '_' + str(int(prs_lvl)) + 'GPHfilter.pkl', 'wb') as f:\n",
    "                        #    pkl.dump((var_troprelthprofs_in[1:,:], var_troprelthprofs_out[1:,:], TROP_theta_array, delta_th_prof, gph_asma), f)\n",
    "    \n",
    "                        with open(SAVEDIR + var_name + 'troprelzprofiles_' + sim_name + '_' + str(lon_bnds) + '_' + str(lat_bnds) + '.pkl', 'wb') as f:\n",
    "                            pkl.dump((np.append(var_troprelzprofs_in[1:,:], var_troprelzprofs_out[1:,:], axis=0), TROP_gph_array, delta_z_prof), f)\n",
    "                            \n",
    "                        # Also save the non-interpolated values\n",
    "                        with open(SAVEDIR + var_name + '_1d_nointerpvals_' + sim_name + '_' + str(lon_bnds) + '_' + str(lat_bnds) + '.pkl', 'wb') as f:\n",
    "                            pkl.dump((var_1d, z_1d, troprelz_1d, theta_1d, tropreltheta_1d), f)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30af937-ca18-41e1-b80b-050b8ee753d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7628e34c-8fc4-49d9-a98b-bd3d42617c65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2024b",
   "language": "python",
   "name": "npl-2024b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
